{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "42b35245-93b6-45ed-bcf8-d9ff22473269",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "3d3bc91774b6b395666c22dc2cca97af6d5dcbe3"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import zlib\n",
    "import itertools\n",
    "import sklearn\n",
    "import itertools\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "#from keras.applications.mobilenet import MobileNet\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import roc_curve\n",
    "#from sklearn.metrics import auc\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "86a1fb25-c9b2-41fe-8bc3-01d91f7054bb",
    "_uuid": "22c127e3183a316ca314946688e21db95a7dc4ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:15<00:00, 188.94it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 193.97it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 197.84it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 192.38it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 190.42it/s]\n",
      "100%|██████████| 3000/3000 [00:16<00:00, 187.19it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 188.46it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 194.58it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 190.61it/s]\n",
      "100%|██████████| 3000/3000 [00:16<00:00, 186.74it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 193.54it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 190.94it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 192.27it/s]\n",
      "100%|██████████| 3000/3000 [00:14<00:00, 206.33it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 189.54it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 191.18it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 190.57it/s]\n",
      "100%|██████████| 3000/3000 [00:16<00:00, 181.18it/s]\n",
      "100%|██████████| 3000/3000 [00:16<00:00, 186.07it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 190.94it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 193.21it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 193.13it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 195.37it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 193.28it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 191.47it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 193.76it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 193.24it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 192.68it/s]\n",
      "100%|██████████| 3000/3000 [00:15<00:00, 190.57it/s]\n"
     ]
    }
   ],
   "source": [
    "imageSize=50\n",
    "train_dir = \"./asl_alphabet_train/\"\n",
    "test_dir =  \"./asl_alphabet_test/\"\n",
    "from tqdm import tqdm\n",
    "def get_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName in ['A']:\n",
    "                label = 0\n",
    "            elif folderName in ['B']:\n",
    "                label = 1\n",
    "            elif folderName in ['C']:\n",
    "                label = 2\n",
    "            elif folderName in ['D']:\n",
    "                label = 3\n",
    "            elif folderName in ['E']:\n",
    "                label = 4\n",
    "            elif folderName in ['F']:\n",
    "                label = 5\n",
    "            elif folderName in ['G']:\n",
    "                label = 6\n",
    "            elif folderName in ['H']:\n",
    "                label = 7\n",
    "            elif folderName in ['I']:\n",
    "                label = 8\n",
    "            elif folderName in ['J']:\n",
    "                label = 9\n",
    "            elif folderName in ['K']:\n",
    "                label = 10\n",
    "            elif folderName in ['L']:\n",
    "                label = 11\n",
    "            elif folderName in ['M']:\n",
    "                label = 12\n",
    "            elif folderName in ['N']:\n",
    "                label = 13\n",
    "            elif folderName in ['O']:\n",
    "                label = 14\n",
    "            elif folderName in ['P']:\n",
    "                label = 15\n",
    "            elif folderName in ['Q']:\n",
    "                label = 16\n",
    "            elif folderName in ['R']:\n",
    "                label = 17\n",
    "            elif folderName in ['S']:\n",
    "                label = 18\n",
    "            elif folderName in ['T']:\n",
    "                label = 19\n",
    "            elif folderName in ['U']:\n",
    "                label = 20\n",
    "            elif folderName in ['V']:\n",
    "                label = 21\n",
    "            elif folderName in ['W']:\n",
    "                label = 22\n",
    "            elif folderName in ['X']:\n",
    "                label = 23\n",
    "            elif folderName in ['Y']:\n",
    "                label = 24\n",
    "            elif folderName in ['Z']:\n",
    "                label = 25\n",
    "            elif folderName in ['del']:\n",
    "                label = 26\n",
    "            elif folderName in ['nothing']:\n",
    "                label = 27\n",
    "            elif folderName in ['space']:\n",
    "                label = 28           \n",
    "            else:\n",
    "                label = 29\n",
    "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
    "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y\n",
    "X_train, y_train = get_data(train_dir) \n",
    "#X_test, y_test= get_data(test_dir) # Too few images\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2) \n",
    "\n",
    "# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_trainHot = to_categorical(y_train, num_classes = 30)\n",
    "y_testHot = to_categorical(y_test, num_classes = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "416ed5f0-5aa3-4d80-a91b-3f16b450a495",
    "_uuid": "676667e7c2b33f134ed685202b2f79bffa3b1734"
   },
   "outputs": [],
   "source": [
    "# Shuffle data to permit further subsampling\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_trainHot = shuffle(X_train, y_trainHot, random_state=13)\n",
    "X_test, y_testHot = shuffle(X_test, y_testHot, random_state=13)\n",
    "X_train = X_train[:30000]\n",
    "X_test = X_test[:30000]\n",
    "y_trainHot = y_trainHot[:30000]\n",
    "y_testHot = y_testHot[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "5c2b5fc4-e1af-4dfe-a928-8a8076c73d59",
    "_uuid": "992129dbd3c7695bdd2e2497a6a56da0227c8c0d"
   },
   "outputs": [],
   "source": [
    "# Helper Functions  Learning Curves and Confusion Matrix\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./accuracy_curve.png')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./loss_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainHot.shape\n",
    "# print(keras.__version__)\n",
    "# np.reshape(y_train, (69600,30))\n",
    "class_weight1\n",
    "from sklearn.utils import class_weight\n",
    "weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weight = {i : weight[i] for i in range(29)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0126582278481013,\n",
       " 1: 1.0062893081761006,\n",
       " 2: 0.9828009828009828,\n",
       " 3: 0.9913258983890955,\n",
       " 4: 1.0050251256281406,\n",
       " 5: 1.008827238335435,\n",
       " 6: 0.9828009828009828,\n",
       " 7: 0.9828009828009828,\n",
       " 8: 1.00418410041841,\n",
       " 9: 1.0169491525423728,\n",
       " 10: 0.9983361064891847,\n",
       " 11: 1.008827238335435,\n",
       " 12: 1.0037641154328734,\n",
       " 13: 0.9913258983890955,\n",
       " 14: 0.9799918334013883,\n",
       " 15: 1.0062893081761006,\n",
       " 16: 0.9933774834437086,\n",
       " 17: 1.008827238335435,\n",
       " 18: 1.0,\n",
       " 19: 1.0062893081761006,\n",
       " 20: 1.0037641154328734,\n",
       " 21: 1.0126582278481013,\n",
       " 22: 1.0037641154328734,\n",
       " 23: 0.9954375777685608,\n",
       " 24: 0.9900990099009901,\n",
       " 25: 1.0062893081761006,\n",
       " 26: 1.0067114093959733,\n",
       " 27: 0.9983361064891847,\n",
       " 28: 1.0037641154328734,\n",
       " 29: 0.9799918334013883}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d9c6929-3f64-4d4e-a82b-362602641156",
    "_uuid": "46be241c508bd8f733fd41b84fa0d4d12ff67b33"
   },
   "source": [
    "*Step 5: Evaluate Classification Models*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3dac612a-0543-47a7-b9be-9a45820b0473",
    "_uuid": "7bb6dff5a30e1644bbfffa0a7c7b5992df5a494c"
   },
   "source": [
    "Transfer learning w/ VGG16 Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_cell_guid": "da473dc4-7e79-4be0-97aa-c7cca6e8aa43",
    "_uuid": "1b8d8acad18ea6c063c61c50d84c5c65f8678b21",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 50, 50, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 14,730,078\n",
      "Trainable params: 15,390\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 263s 280ms/step - loss: 2.6903 - accuracy: 0.3434 - val_loss: 1.6280 - val_accuracy: 0.6560\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 260s 277ms/step - loss: 1.4613 - accuracy: 0.7107 - val_loss: 1.1846 - val_accuracy: 0.7571\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 254s 271ms/step - loss: 1.0950 - accuracy: 0.7846 - val_loss: 0.9554 - val_accuracy: 0.8091\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 243s 259ms/step - loss: 0.8996 - accuracy: 0.8231 - val_loss: 0.8102 - val_accuracy: 0.8334\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 242s 258ms/step - loss: 0.7666 - accuracy: 0.8469 - val_loss: 0.7123 - val_accuracy: 0.8533\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1921s 2s/step - loss: 0.6649 - accuracy: 0.8660 - val_loss: 0.6344 - val_accuracy: 0.8666\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 243s 259ms/step - loss: 0.6079 - accuracy: 0.8780 - val_loss: 0.5771 - val_accuracy: 0.8764\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 266s 284ms/step - loss: 0.5418 - accuracy: 0.8918 - val_loss: 0.5278 - val_accuracy: 0.8904\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 277s 296ms/step - loss: 0.4946 - accuracy: 0.9018 - val_loss: 0.4843 - val_accuracy: 0.9002\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 278s 297ms/step - loss: 0.4598 - accuracy: 0.9081 - val_loss: 0.4550 - val_accuracy: 0.9078\n"
     ]
    }
   ],
   "source": [
    "map_characters1 = map_characters\n",
    "class_weight1 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weight_path1 = './vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weight_path2 = './inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pretrained_model_1 = VGG16(weights = weight_path1, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "# pretrained_model_2 = InceptionV3(weights = weight_path2, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = keras.optimizers.Adam()\n",
    "optimizer2 = keras.optimizers.RMSprop(lr=0.0001)\n",
    "def pretrainedNetwork(xtrain,ytrain,xtest,ytest,pretrainedmodel,\n",
    "                      pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n",
    "    base_model = pretrained_model_1 # Topless\n",
    "    # Add top layer\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(numclasses, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    # Train top layer\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "    model.summary()\n",
    "    # Fit model\n",
    "    history = model.fit(xtrain,ytrain, epochs=numepochs, class_weight=classweight, \n",
    "                        validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n",
    "#     # Evaluate model\n",
    "#     score = model.evaluate(xtest,ytest, verbose=0)\n",
    "#     print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
    "#     y_pred = model.predict(xtest)\n",
    "#     print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], \n",
    "#                                                       np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
    "#     Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "#     Y_true = np.argmax(ytest,axis = 1) \n",
    "#     confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "#     plotKerasLearningCurve()\n",
    "#     plt.show()\n",
    "#     plot_learning_curve(history)\n",
    "#     plt.show()\n",
    "#     plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
    "#     plt.show()\n",
    "    return model\n",
    "model = pretrainedNetwork(X_train, np.array(y_trainHot), X_test, np.array(y_testHot),pretrained_model_1,\n",
    "                  weight_path1,weight,30,10,optimizer1,map_characters1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4df933c-a0c0-435e-baeb-42fbec811394",
    "_uuid": "f8647a019c1fe3ed13a4866fe9314b3cb833f278"
   },
   "source": [
    "Great, we were able to interpret the signs with an accuracy rate of approximately 92%.  That is much better than random chance given that there were 26 different signs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1468fed2-8194-4d54-84d1-fbd7549ecdf0",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "d1d747b2c84f43929f9fb75af8f739248b90279d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To Do: (1) try using more than 30000 of the 87000 images; (2) try using larger images; (3) try using different network architectures "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
