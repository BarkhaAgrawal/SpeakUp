{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-89c5eeb2124b>:47: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  image_data = cv2.imencode('.jpg', resized_image)[1].tostring()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter:  NOTHING  Score:  0.75323164\n",
      "Current word:  \n",
      "Letter:  NOTHING  Score:  0.36949465\n",
      "Current word:  \n",
      "Letter:  NOTHING  Score:  0.56068605\n",
      "Current word:  \n",
      "Letter:  X  Score:  0.20182648\n",
      "Current word:  \n",
      "hello\n",
      "Letter:  V  Score:  0.47057018\n",
      "Current word:  X\n",
      "hello\n",
      "Letter:  W  Score:  0.17846954\n",
      "Current word:  XV\n",
      "hello\n",
      "Letter:  B  Score:  0.33087954\n",
      "Current word:  XVW\n",
      "hello\n",
      "Letter:  X  Score:  0.27536926\n",
      "Current word:  XVWB\n",
      "hello\n",
      "Letter:  X  Score:  0.27021965\n",
      "Current word:  XVWBX\n",
      "hello\n",
      "Letter:  X  Score:  0.23154528\n",
      "Current word:  XVWBXX\n",
      "hello\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-89c5eeb2124b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# Display live feed until ESC key is pressed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# Press ESC to exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mkeypress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;31m# Flip the image laterally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\t\t\t\t# Import OpenCV for image processing\n",
    "import sys\t\t\t\t# Import for time\n",
    "import os\t\t\t\t# Import for reading files\n",
    "import threading\t\t# Import for separate thread for image classification\n",
    "import numpy as np \t\t# Import for converting vectors\n",
    "# from gtts import gTTS   # Import Google Text to Speech\n",
    "#import spell_checker\t# Import for spelling corrections\n",
    "from azure.cognitiveservices.speech import AudioDataStream, SpeechConfig, SpeechSynthesizer, SpeechSynthesisOutputFormat\n",
    "from azure.cognitiveservices.speech.audio import AudioOutputConfig\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "speech_config = SpeechConfig(subscription=\"8061a18adc5a4aaf8cc1a3d69666b49e\", region=\"eastus\")\n",
    "# Disable tensorflow compilation warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf # Import tensorflow for Inception Net's backend\n",
    "\n",
    "# Language in which you want to convert\n",
    "language = 'en'\n",
    "\n",
    "# Get a live stream from the webcam\n",
    "live_stream = cv2.VideoCapture(0)\n",
    "\n",
    "# Word for which letters are currently being signed\n",
    "current_word = \"\"\n",
    "\n",
    "# Load training labels file\n",
    "label_lines = [line.rstrip() for line in tf.compat.v1.gfile.GFile(\"training_set_labels.txt\")]\n",
    "\n",
    "# Load trained model's graph\n",
    "with tf.compat.v1.gfile.FastGFile(\"trained_model_graph.pb\", 'rb') as f:\n",
    "\t# Define a tensorflow graph\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "    # Read and import line by line from the trained model's graph\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "def predict(image_data):\n",
    "\n",
    "\t# Focus on Region of Interest (Image within the bounding box)\n",
    "\tresized_image = image_data[70:350, 70:350]\n",
    "\t\n",
    "\t# Resize to 200 x 200\n",
    "\tresized_image = cv2.resize(resized_image, (200, 200))\n",
    "\t\n",
    "\timage_data = cv2.imencode('.jpg', resized_image)[1].tostring()\n",
    "\n",
    "\tpredictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "\t# Sort to show labels of first prediction in order of confidence\n",
    "\ttop_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "\n",
    "\tmax_score = 0.0\n",
    "\tres = ''\n",
    "\tfor node_id in top_k:\n",
    "\t\t# Just to get rid of the Z error for demo\n",
    "\t\tif label_lines[node_id].upper() == 'Z':\n",
    "\t\t\thuman_string = label_lines[node_id+1]\n",
    "\t\telse:\n",
    "\t\t\thuman_string = label_lines[node_id]\n",
    "\t\tscore = predictions[0][node_id]\n",
    "\t\tif score > max_score:\t\n",
    "\t\t\tmax_score = score\n",
    "\t\t\tres = human_string\n",
    "\n",
    "\treturn res, max_score\n",
    "\n",
    "def speak_letter(letter):    \n",
    "\t# Create the text to be spoken\n",
    "    prediction_text = letter\n",
    "    audio_config = AudioOutputConfig(filename=\"file.wav\")\n",
    "    synthesizer = SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    synthesizer.speak_text_async(prediction_text)\n",
    "    song = AudioSegment.from_wav(\"file.wav\")\n",
    "    play(song)\n",
    "    \n",
    "with  tf.compat.v1.Session() as sess:\n",
    "\t# Feed the image_data as input to the graph and get first prediction\n",
    "\tsoftmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "\t# Global variable to keep track of time\n",
    "\ttime_counter = 0\n",
    "\n",
    "\t# Flag to check if 'c' is pressed\n",
    "\tcaptureFlag = False\n",
    "\n",
    "\t# Toggle real time processing\n",
    "\trealTime = True\n",
    "\n",
    "\t# Toggle spell checking\n",
    "\tspell_check = False\n",
    "\tm = 0\n",
    "\t# Infinite loop\n",
    "\twhile True:\n",
    "\n",
    "\t\t# Display live feed until ESC key is pressed\n",
    "\t\t# Press ESC to exit\n",
    "\t\tkeypress = cv2.waitKey(1)\n",
    "\n",
    "\t\t# Flip the image laterally\n",
    "\t\t#img = cv2.flip(img, 1)\n",
    "\t\t\n",
    "\t\t# TESTING:\n",
    "\t\t#threading.Timer(5.0, printit).start()\n",
    "\t\t\n",
    "\t\t# Read a single frame from the live feed\n",
    "\t\timg = live_stream.read()[1]\n",
    "\n",
    "\t\t# Set a region of interest\n",
    "\t\tcv2.rectangle(img, (70, 70), (350, 350), (0,255,0), 2)\n",
    "\n",
    "\t\t# Show the live stream\n",
    "\t\tcv2.imshow(\"Live Stream\", img)\n",
    "\t\t\n",
    "\t\t# To get time intervals\n",
    "\t\tif time_counter % 45 == 0 and realTime:\n",
    "\n",
    "\t\t\tletter, score = predict(img)\n",
    "\t\t\t#cv2.imshow(\"Resized Image\", img)\n",
    "\t\t\tprint(\"Letter: \",letter.upper(), \" Score: \", score)\n",
    "\t\t\tprint(\"Current word: \", current_word)\n",
    "\n",
    "\t\t\tif letter.upper() != 'NOTHING' and letter.upper() != 'SPACE' and letter.upper() != 'DEL':\n",
    "\t\t\t\tcurrent_word += letter.upper()\n",
    "\t\t\t\tspeak_letter(letter)\n",
    "\n",
    "\t\t\t# Say the letter out loud\n",
    "\t\t\telif letter.upper() == 'SPACE':\n",
    "\t\t\t\tif len(current_word) > 0:\n",
    "\t\t\t\t\tif spell_check:\n",
    "\t\t\t\t\t\tspeak_letter(spell_checker.correction(current_word),m)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tspeak_letter(current_word,m)\n",
    "\t\t\t\tcurrent_word = \"\"\n",
    "\n",
    "\t\t\telif letter.upper() == 'DEL':\n",
    "\t\t\t\tif len(current_word) > 0:\n",
    "\t\t\t\t\tcurrent_word = current_word[:-1]\n",
    "\t\t\t\n",
    "\t\t\telif letter.upper() == 'NOTHING':\n",
    "\t\t\t\tpass\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"UNEXPECTED INPUT: \", letter.upper())\n",
    "\n",
    "\n",
    "\t\t# 'C' is pressed\n",
    "\t\tif keypress == ord('c'):\n",
    "\t\t\tcaptureFlag = True\n",
    "\t\t\trealTime = False\n",
    "\n",
    "\t\t# 'R' is pressed\n",
    "\t\tif keypress == ord('r'):\n",
    "\t\t\trealTime = True\n",
    "\n",
    "\t\tif captureFlag:\n",
    "\t\t\tcaptureFlag = False\n",
    "\n",
    "\t\t\t# Show the image considered for classification\n",
    "\t\t\t# Just for Debugging\n",
    "\t\t\t#cv2.imshow(\"Resized Image\", resized_image)\n",
    "\n",
    "\t\t\t# Get the letter and the score\n",
    "\t\t\tletter, score = predict(img)\n",
    "\t\t\tprint(\"Letter: \",letter.upper(), \" Score: \", score)\n",
    "\t\t\tprint(\"Current word: \", current_word)\n",
    "\n",
    "\n",
    "\t\t\tif letter.upper() != 'NOTHING' and letter.upper() != 'SPACE' and letter.upper() != 'DEL':\n",
    "\t\t\t\tcurrent_word += letter.upper()\n",
    "\t\t\t\tspeak_letter(letter)\n",
    "\n",
    "\t\t\t# Say the letter out loud\n",
    "\t\t\telif letter.upper() == 'SPACE':\n",
    "\t\t\t\tif len(current_word) > 0:\n",
    "\t\t\t\t\tif spell_check:\n",
    "\t\t\t\t\t\tspeak_letter(spell_checker.correction(current_word),m)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tspeak_letter(current_word,m)\n",
    "\t\t\t\tcurrent_word = \"\"\n",
    "\n",
    "\t\t\telif letter.upper() == 'DEL':\n",
    "\t\t\t\tif len(current_word) > 0:\n",
    "\t\t\t\t\tcurrent_word = current_word[:-1]\n",
    "\t\t\t\n",
    "\t\t\telif letter.upper() == 'NOTHING':\n",
    "\t\t\t\tpass\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"UNEXPECTED INPUT: \", letter.upper())\n",
    "        \n",
    "\t\t# If ESC is pressed\n",
    "\t\tif keypress == 27:\n",
    "\t\t\texit(0)\t\n",
    "\n",
    "\t\t# Update time\n",
    "\t\ttime_counter = time_counter + 1\n",
    "\n",
    "\n",
    "# Stop using camers\n",
    "live_stream.release()\n",
    "# Destroy windows created by OpenCV\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
